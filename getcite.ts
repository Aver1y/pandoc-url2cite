#!/usr/bin/env node

/// <reference path="untyped.d.ts" />

import pandoc, {
	EltMap,
	Elt,
	Inline,
	Block,
	Cite,
	Link,
	Str,
	Space
} from "pandoc-filter";
import * as fs from "fs";
import cjs from "citation-js";
import {
	PandocMetaMap,
	fromMeta,
	fromMetaMap,
	toMeta,
	makeTransformer,
	isURL
} from "./util";

/** written to CWD from which pandoc is called */
const citationCachePath = "citation-cache.json";

/** type of the citation-cache.json file */
let cache: {
	_info: string;
	urls: { [url: string]: { fetched: string; bibtex: string[]; csl: any } };
} = {
	_info:
		"Auto-generated by pandoc-url2cite. Feel free to modify, keys will never be overwritten.",
	urls: {}
};

async function getCslForUrl(url: string) {
	// uses zotero extractors from https://github.com/zotero/translators to get information from URLs
	// https://www.mediawiki.org/wiki/Citoid/API
	// it should be possible to run a citoid or [zotero translation-server](https://github.com/zotero/translation-server) locally,
	// but this works fine for now and is much less fragile than trying to run that server in e.g. docker automatically.
	console.warn("fetching citation from url", url);
	const res = await fetch(
		`https://en.wikipedia.org/api/rest_v1/data/citation/bibtex/${encodeURIComponent(
			url
		)}`
	);

	if (!res.ok) {
		throw Error(
			`could not fetch citation from ${url}: ${await res.text()}`
		);
	}
	const bibtex = await res.text();

	try {
		// Citoid does not have CSL output, so convert bibtex to CSL JSON format
		var cbb = new cjs(bibtex.replace("{\\textbar}", "--")); // https://github.com/larsgw/citation.js/issues/194
	} catch (e) {
		console.warn("could not parse bibtex: ", bibtex);
		throw e;
	}

	if (cbb.data.length !== 1)
		throw Error("got != 1 bibtex entries: " + bibtex);
	cbb.data[0].id = url;
	const [csl] = cbb.get({ format: "real", type: "json", style: "csl" });
	delete csl._graph; // would be unnecessary bloat in json

	return {
		fetched: new Date().toJSON(),
		bibtex: bibtex.replace(/\t/g, "   ").split("\n"),
		csl
	};
}

async function getCslForUrlCached(url: string) {
	if (url in cache.urls) return;
	cache.urls[url] = await getCslForUrl(url);
	writeCache();
}

/**
 * transform the pandoc document AST to fetch missing citations
 */
const astTransformer = makeTransformer(async (el, _outputFormat, meta) => {
	if (el.t === "Cite") {
		if (typeof meta.citekeys !== "object" || Array.isArray(meta.citekeys))
			throw Error("No citekeys in document meta");
		const [citations, _inline] = el.c;
		for (const citation of citations) {
			const id = citation.citationId;
			const url = isURL(id) ? id : meta.citekeys[id];
			if (!url) throw `Error: Could not find URL for @${id}`;
			if (typeof url !== "string")
				throw Error(`url for ${id} is not string: ${url}`);
			await getCslForUrlCached(url);
			// replace the citation id with the url
			citation.citationId = url;
		}
	} else if (el.t === "Link") {
		if (meta.url2cite && typeof meta.url2cite !== "string")
			throw Error("unsupported value of url2cite");
		const [[id, classes, kv], inline, [url, targetTitle]] = el.c;

		if (
			meta.url2cite === "all-links" ||
			classes.includes("url2cite") ||
			/\burl2cite\b/.test(targetTitle)
		) {
			if (
				classes.includes("no-url2cite") ||
				/\bno-url2cite\b/.test(targetTitle)
			) {
				// disabling per link overrides enabling
				return;
			}
			// here we basically convert a link of form [text](href)
			// to one of form [text [@{href}]](href)
			await getCslForUrlCached(url);
			const cite = Cite(
				[
					{
						citationSuffix: [],
						citationNoteNum: 0,
						citationMode: {
							t: "NormalCitation"
						} as any, // wrong typings
						citationPrefix: [],
						citationId: url,
						citationHash: 0
					}
				],
				[]
			);

			const e: Elt<"Link"> = Link(
				[id, classes, kv],
				[...inline, Space(), cite],
				[url, targetTitle]
			);

			return e;
		}
	}
});

function writeCache() {
	fs.writeFileSync(citationCachePath, JSON.stringify(cache, null, "\t"));
}

async function go() {
	try {
		cache = JSON.parse(fs.readFileSync(citationCachePath, "utf8"));
	} catch {}
	// parse AST from stdin
	const data = JSON.parse(fs.readFileSync(0, "utf8"));
	const format = process.argv.length > 2 ? process.argv[2] : "";
	// untyped https://github.com/mvhenderson/pandoc-filter-node/issues/9
	const res = await (pandoc as any).filterAsync(data, astTransformer, format);
	console.warn(
		`got all ${Object.keys(cache.urls).length} citations from URLs`
	);

	// add all cached references to the frontmatter. pandoc-citeproc will handle (ignore) unused keys.
	res.meta.references = toMeta(
		Object.entries(cache.urls).map(([url, { csl }]) => csl)
	);
	process.stdout.write(JSON.stringify(res));
}

go().catch(e => {
	console.error("extraction error", e);
	process.exit(1);
});
