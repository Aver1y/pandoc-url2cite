#!/usr/bin/env node

/// <reference path="untyped.d.ts" />

import pandoc, {
	EltMap,
	Elt,
	Inline,
	Block,
	Cite,
	Link,
	Str,
	Space,
	Para
} from "pandoc-filter";
import * as fs from "fs";
import cjs from "citation-js";
import {
	PandocMetaMap,
	fromMeta,
	fromMetaMap,
	toMeta,
	makeTransformer,
	isURL
} from "./util";

/** written to CWD from which pandoc is called */
const citationCachePath = "citation-cache.json";

/** type of the citation-cache.json file */
let cache: {
	_info: string;
	urls: { [url: string]: { fetched: string; bibtex: string[]; csl: any } };
} = {
	_info:
		"Auto-generated by pandoc-url2cite. Feel free to modify, keys will never be overwritten.",
	urls: {}
};

const citekeys: { [key: string]: string } = {};

async function getCslForUrl(url: string) {
	// uses zotero extractors from https://github.com/zotero/translators to get information from URLs
	// https://www.mediawiki.org/wiki/Citoid/API
	// it should be possible to run a citoid or [zotero translation-server](https://github.com/zotero/translation-server) locally,
	// but this works fine for now and is much less fragile than trying to run that server in e.g. docker automatically.
	console.warn("fetching citation from url", url);
	const res = await fetch(
		`https://en.wikipedia.org/api/rest_v1/data/citation/bibtex/${encodeURIComponent(
			url
		)}`
	);

	if (!res.ok) {
		throw Error(
			`could not fetch citation from ${url}: ${await res.text()}`
		);
	}
	const bibtex = await res.text();

	try {
		// Citoid does not have CSL output, so convert bibtex to CSL JSON format
		var cbb = new cjs(bibtex.replace("{\\textbar}", "--")); // https://github.com/larsgw/citation.js/issues/194
	} catch (e) {
		console.warn("could not parse bibtex: ", bibtex);
		throw e;
	}

	if (cbb.data.length !== 1)
		throw Error("got != 1 bibtex entries: " + bibtex);
	cbb.data[0].id = url;
	const [csl] = cbb.get({ format: "real", type: "json", style: "csl" });
	delete csl._graph; // would be unnecessary bloat in json

	return {
		fetched: new Date().toJSON(),
		bibtex: bibtex.replace(/\t/g, "   ").split("\n"),
		csl
	};
}

async function getCslForUrlCached(url: string) {
	if (url in cache.urls) return;
	cache.urls[url] = await getCslForUrl(url);
	writeCache();
}

// Only needed for link syntax (not pandoc cite syntax)
//
// Since pandoc (with citations extension) does not parse `[@name]: http://...` as
// [link reference definitions](https://spec.commonmark.org/0.29/#link-reference-definition)
// we convert them ourselves. This leads to small inconsistencies in what you can do:
// 1. They need to be in their own paragraph.
// 2. link title is not parsed (but also would not be used anyways)
const extractCiteKeys = makeTransformer(async (el, _outputFormat, meta) => {
	if (el.t === "Para") {
		while (
			el.c.length >= 3 &&
			el.c[0].t === "Cite" &&
			el.c[0].c[0].length === 1 &&
			el.c[1].t === "Str" &&
			el.c[1].c === ":"
		) {
			const sp = el.c[2].t === "Space" ? 3 : 2;
			const v = el.c[sp];
			if (v.t === "Str") {
				const key = el.c[0].c[0][0].citationId;
				const url = v.c;
				if (key in citekeys)
					console.warn("warning: duplicate citekey", key);
				citekeys[key] = url;
				// found citation, add it to citekeys and remove it from document
				el.c = el.c.slice(sp + 1);
				if (el.c.length > 0 && el.c[0].t === "SoftBreak") el.c.shift();
			}
		}
		return el;
	}
});
/**
 * transform the pandoc document AST to fetch missing citations
 */
const astTransformer = makeTransformer(async (el, _outputFormat, getMeta) => {
	if (el.t === "Cite") {
		const [citations, _inline] = el.c;
		for (const citation of citations) {
			const id = citation.citationId;
			const url = isURL(id) ? id : citekeys[id];
			if (!url) throw `Error: Could not find URL for @${id}`;
			if (typeof url !== "string")
				throw Error(`url for ${id} is not string: ${url}`);
			await getCslForUrlCached(url);
			// replace the citation id with the url
			citation.citationId = url;
		}
	} else if (el.t === "Link") {
		const meta = getMeta();
		if (meta.url2cite && typeof meta.url2cite !== "string")
			throw Error("unsupported value of url2cite");
		const [[id, classes, kv], inline, [url, targetTitle]] = el.c;

		if (
			meta.url2cite === "all-links" ||
			classes.includes("url2cite") ||
			/\burl2cite\b/.test(targetTitle)
		) {
			if (
				classes.includes("no-url2cite") ||
				/\bno-url2cite\b/.test(targetTitle)
			) {
				// disabling per link overrides enabling
				return;
			}
			if (!isURL(url)) {
				// probably a relative URL. Keep it as is
				return;
			}
			// here we basically convert a link of form [text](href)
			// to one of form [text [@{href}]](href)
			await getCslForUrlCached(url);
			const cite = Cite(
				[
					{
						citationSuffix: [],
						citationNoteNum: 0,
						citationMode: {
							t: "NormalCitation"
						} as any, // wrong typings
						citationPrefix: [],
						citationId: url,
						citationHash: 0
					}
				],
				[]
			);

			const e: Elt<"Link"> = Link(
				[id, classes, kv],
				[...inline, Space(), cite],
				[url, targetTitle]
			);

			return e;
		}
	}
});

function writeCache() {
	fs.writeFileSync(citationCachePath, JSON.stringify(cache, null, "\t"));
}

async function go() {
	if (["--help", "--version", "-h", "-v"].includes(process.argv[2] || "-h")) {
		const { version, homepage } = require("../package.json");
		console.error(`pandoc-url2cite v${version}`);
		console.error(`Usage: ${homepage}`);
		return;
	}
	try {
		cache = JSON.parse(fs.readFileSync(citationCachePath, "utf8"));
	} catch {}
	// parse AST from stdin
	let data = JSON.parse(fs.readFileSync(0, "utf8"));
	const format = process.argv.length > 2 ? process.argv[2] : "";

	// untyped https://github.com/mvhenderson/pandoc-filter-node/issues/9
	data = await (pandoc as any).filterAsync(data, extractCiteKeys, format);
	data = await (pandoc as any).filterAsync(data, astTransformer, format);
	console.warn(
		`got all ${Object.keys(cache.urls).length} citations from URLs`
	);

	// add all cached references to the frontmatter. pandoc-citeproc will handle (ignore) unused keys.
	data.meta.references = toMeta(
		Object.entries(cache.urls).map(([url, { csl }]) => csl)
	);
	process.stdout.write(JSON.stringify(data));
}

go().catch(e => {
	console.error("extraction error", e);
	process.exit(1);
});
